import streamlit as st
import pandas as pd
import requests
from urllib.parse import urlencode
import plotly.express as px

# ----------------------------------------------------------
# PAGE CONFIG
# ----------------------------------------------------------
st.set_page_config(page_title="×œ×•×— ×‘×§×¨×” - ×¨×™×§×•×œ×™× ×œ×¨×›×‘×™×", layout="wide")

st.title("ğŸ“Š ×œ×•×— ×‘×§×¨×” - ×¨×™×§×•×œ×™× ×œ×¨×›×‘×™× ×‘×™×©×¨××œ")
st.write("× ×ª×•× ×™× ×—×™×™× ×™×©×™×¨×•×ª ×-API ×©×œ × ×ª×•× ×™ ×”×××©×œ×” ×”×¤×ª×•×—×™×.")

# ----------------------------------------------------------
# CONSTANTS â€“ API RESOURCE IDs
# ----------------------------------------------------------
RECALLS_RID = "2c33523f-87aa-44ec-a736-edbb0a82975e"
PRIVATE_RID = "053cea08-09bc-40ec-8f7a-156f0677aff3"
UNATTENDED_RID = "36bf1404-0be4-49d2-82dc-2f1ead4a8b93"

API_BASE = "https://data.gov.il/api/3/action/datastore_search"


# ----------------------------------------------------------
# API FETCHER WITH PAGINATION
# ----------------------------------------------------------
@st.cache_data(show_spinner=True)
def fetch_full_table(resource_id, max_rows=50000):
    """Fetches up to max_rows rows from the CKAN API with pagination."""
    all_records = []
    limit = 5000
    offset = 0

    while True:
        params = {
            "resource_id": resource_id,
            "limit": limit,
            "offset": offset
        }

        url = API_BASE + "?" + urlencode(params)
        response = requests.get(url)

        if response.status_code != 200:
            st.error(f"×©×’×™××ª API: {response.text}")
            break

        data = response.json()["result"]["records"]
        if not data:
            break

        all_records.extend(data)
        offset += limit

        if len(all_records) >= max_rows:
            break

    df = pd.DataFrame(all_records)
    return df


# ----------------------------------------------------------
# LOAD DATA (LIMITED FOR STREAMLIT PERFORMANCE)
# ----------------------------------------------------------
st.sidebar.header("âš™ï¸ ×”×’×“×¨×•×ª")
MAX_ROWS = st.sidebar.slider("××§×¡×™××•× ×©×•×¨×•×ª ×œ×˜×¢×™× ×” ×œ×›×œ ×˜×‘×œ×”:", 5000, 150000, 50000)

with st.spinner("××•×¨×™×“ × ×ª×•× ×™× ×—×™×™× ×-data.gov.il..."):
    recalls = fetch_full_table(RECALLS_RID, MAX_ROWS)
    private = fetch_full_table(PRIVATE_RID, MAX_ROWS)
    unattended = fetch_full_table(UNATTENDED_RID, MAX_ROWS)

st.success("×”× ×ª×•× ×™× × ×˜×¢× ×• ×‘×”×¦×œ×—×”.")

# ----------------------------------------------------------
# CLEAN COLUMN NAMES (normalize to lowercase to match API)
# ----------------------------------------------------------
recalls.columns = recalls.columns.str.lower()
private.columns = private.columns.str.lower()
unattended.columns = unattended.columns.str.lower()

# Hebrew column mapping
HEBREW_COLUMNS = {
    # Unattended table
    "mispar_rechev": "××¡×¤×¨ ×¨×›×‘",
    "recall_id": "××–×”×” ×¨×™×§×•×œ",
    "sug_recall": "×¡×•×’ ×¨×™×§×•×œ",
    "sug_takala": "×¡×•×’ ×ª×§×œ×”",
    "teur_takala": "×ª×™××•×¨ ×ª×§×œ×”",
    "taarich_pticha": "×ª××¨×™×š ×¤×ª×™×—×”",
    
    # Recalls table
    "tozar_cd": "×§×•×“ ×™×¦×¨×Ÿ",
    "tozar_teur": "×™×¦×¨×Ÿ",
    "degem": "×“×’×",
    "shnat_recall": "×©× ×ª ×¨×™×§×•×œ",
    "build_begin_a": "×ª×—×™×œ×ª ×™×™×¦×•×¨",
    "build_end_a": "×¡×•×£ ×™×™×¦×•×¨",
    "ofen_tikun": "××•×¤×Ÿ ×ª×™×§×•×Ÿ",
    "tkina_eu": "×ª×§× ×” EU",
    "yevuan_teur": "×™×‘×•××Ÿ",
    "telephone": "×˜×œ×¤×•×Ÿ",
    "website": "××ª×¨",
    
    # Private vehicles table
    "tozeret_cd": "×§×•×“ ×™×¦×¨×Ÿ",
    "sug_degem": "×¡×•×’ ×“×’×",
    "tozeret_nm": "×™×¦×¨×Ÿ",
    "degem_cd": "×§×•×“ ×“×’×",
    "degem_nm": "×“×’×",
    "ramat_gimur": "×¨××ª ×’×™××•×¨",
    "shnat_yitzur": "×©× ×ª ×™×™×¦×•×¨",
    "tzeva_rechev": "×¦×‘×¢ ×¨×›×‘",
    "sug_delek_nm": "×¡×•×’ ×“×œ×§",
    "kinuy_mishari": "×›×™× ×•×™ ××¡×—×¨×™"
}


# ----------------------------------------------------------
# PLATE LOOKUP TOOL
# ----------------------------------------------------------
st.subheader("ğŸ” ×‘×“×™×§×ª ××¡×¤×¨ ×¨×™×©×•×™ ×œ×¨×™×§×•×œ×™× ×©×œ× ×˜×•×¤×œ×•")

plate_input = st.text_input("×”×–×Ÿ ××¡×¤×¨ ×¨×™×©×•×™ (×¡×¤×¨×•×ª ×‘×œ×‘×“):")

if plate_input:
    try:
        plate_num = int(plate_input.strip())
        match = unattended[unattended["mispar_rechev"] == plate_num]

        if len(match) > 0:
            st.error("âš ï¸ ×œ×¨×›×‘ ×©×œ×š ×™×© ×¨×™×§×•×œ ×©×œ× ×˜×•×¤×œ!")

            # Merge with recalls to get SUG_TAKALA and TEUR_TAKALA
            match_with_details = match.merge(
                recalls[["recall_id", "sug_takala", "teur_takala"]],
                on="recall_id",
                how="left"
            )

            # Rename columns to Hebrew for display
            display_match = match_with_details[["recall_id", "sug_recall", "sug_takala", "teur_takala", "taarich_pticha"]].copy()
            display_match.columns = [HEBREW_COLUMNS.get(col, col) for col in display_match.columns]
            
            st.write(display_match)
        else:
            st.success("âœ”ï¸ ×”×¨×›×‘ ×©×œ×š ×œ× ××•×¤×™×¢ ×‘×××’×¨ ×”×¨×™×§×•×œ×™× ×©×œ× ×˜×•×¤×œ×•.")
    except:
        st.error("××¡×¤×¨ ×œ× ×ª×§×™×Ÿ.")


# ----------------------------------------------------------
# JOIN: For later graphs
# ----------------------------------------------------------
# Ensure numeric
private["mispar_rechev"] = pd.to_numeric(private["mispar_rechev"], errors="coerce")
unattended["mispar_rechev"] = pd.to_numeric(unattended["mispar_rechev"], errors="coerce")

# Merge by TOZERET_CD (manufacturer) and DEGEM_NM (model)
joined = private.merge(
    recalls,
    left_on=["tozeret_cd", "degem_nm"],
    right_on=["tozar_cd", "degem"],
    how="inner",
    suffixes=("_pr", "_rc")
)


# ----------------------------------------------------------
# SECTIONS (SCROLLABLE, NOT TABS)
# ----------------------------------------------------------
st.write("---")


# ----------------------------------------------------------
# SECTION 1 â€” Which Recall Affected Most Vehicles?
# ----------------------------------------------------------
st.header("ğŸš— ×¨×™×§×•×œ×™× ×©×”×©×¤×™×¢×• ×¢×œ ××¡×¤×¨ ×”×¨×›×‘×™× ×”×’×‘×•×” ×‘×™×•×ª×¨")

recall_counts = (
    joined.groupby(["recall_id", "sug_takala_rc", "teur_takala_rc"])
    .agg(vehicles_affected=("mispar_rechev_pr", "count"))
    .sort_values("vehicles_affected", ascending=False)
    .reset_index()
)

# Rename for display
recall_counts_display = recall_counts.head(20).copy()
recall_counts_display.columns = ["××–×”×” ×¨×™×§×•×œ", "×¡×•×’ ×ª×§×œ×”", "×ª×™××•×¨ ×ª×§×œ×”", "××¡×¤×¨ ×¨×›×‘×™× ××•×©×¤×¢×™×"]

fig1 = px.bar(
    recall_counts_display,
    x="××–×”×” ×¨×™×§×•×œ",
    y="××¡×¤×¨ ×¨×›×‘×™× ××•×©×¤×¢×™×",
    hover_data=["×¡×•×’ ×ª×§×œ×”", "×ª×™××•×¨ ×ª×§×œ×”"],
    title="20 ×”×¨×™×§×•×œ×™× ×”××•×‘×™×œ×™× ×œ×¤×™ ××¡×¤×¨ ×¨×›×‘×™× ××•×©×¤×¢×™×"
)
st.plotly_chart(fig1, use_container_width=True)

st.subheader("ğŸ’¬ ×”×¢×¨×•×ª")
st.text_area("×”×•×¡×£ ×”×¢×¨×•×ª ×¢×œ ×¨×™×§×•×œ×™× ××©×¤×™×¢×™×:", key="comments_1", height=100)

st.write("---")


# ----------------------------------------------------------
# SECTION 2 â€” Recalls Over Time
# ----------------------------------------------------------
st.header("ğŸ“ˆ ×¨×™×§×•×œ×™× ×œ××•×¨×š ×–××Ÿ ×œ×¤×™ ×™×¦×¨×Ÿ")

if "shnat_recall" in recalls.columns:
    recalls["shnat_recall"] = pd.to_numeric(recalls["shnat_recall"], errors="coerce")

trend = (
    recalls.groupby(["shnat_recall", "tozar_teur"])
    .size()
    .reset_index(name="count")
)

# Rename for display
trend_display = trend.copy()
trend_display.columns = ["×©× ×ª ×¨×™×§×•×œ", "×™×¦×¨×Ÿ", "××¡×¤×¨ ×¨×™×§×•×œ×™×"]

fig2 = px.line(
    trend_display,
    x="×©× ×ª ×¨×™×§×•×œ",
    y="××¡×¤×¨ ×¨×™×§×•×œ×™×",
    color="×™×¦×¨×Ÿ",
    title="××¡×¤×¨ ×¨×™×§×•×œ×™× ×œ×¤×™ ×™×¦×¨×Ÿ ×œ××•×¨×š ×–××Ÿ"
)
st.plotly_chart(fig2, use_container_width=True)

st.subheader("ğŸ’¬ ×”×¢×¨×•×ª")
st.text_area("×”×•×¡×£ ×”×¢×¨×•×ª ×¢×œ ××’××•×ª ×¨×™×§×•×œ×™×:", key="comments_2", height=100)

st.write("---")


# ----------------------------------------------------------
# SECTION 3 â€” Importer Performance (Attendance Rates)
# ----------------------------------------------------------
st.header("ğŸ­ ×‘×™×¦×•×¢×™ ×™×‘×•×× ×™× - ××—×•×–×™ ×˜×™×¤×•×œ ×‘×¨×™×§×•×œ×™×")

total_affected = (
    joined.groupby("recall_id")
    .agg(total=("mispar_rechev_pr", "count"))
)

unattended_count = (
    unattended.groupby("recall_id")
    .size()
    .to_frame("unattended")
)

performance = total_affected.join(unattended_count, how="left").fillna(0)
performance["attendance_rate"] = (
    (1 - performance["unattended"] / performance["total"]) * 100
)

# Join importer
performance = performance.merge(
    recalls[["recall_id", "yevuan_teur"]],
    on="recall_id",
    how="left"
)

perf_by_importer = performance.groupby("yevuan_teur")["attendance_rate"].mean().reset_index()
perf_by_importer.columns = ["×™×‘×•××Ÿ", "××—×•×– ×××•×¦×¢ ×©×œ ×˜×™×¤×•×œ ×‘×¨×™×§×•×œ×™×"]

fig3 = px.bar(
    perf_by_importer,
    x="×™×‘×•××Ÿ",
    y="××—×•×– ×××•×¦×¢ ×©×œ ×˜×™×¤×•×œ ×‘×¨×™×§×•×œ×™×",
    title="×‘×™×¦×•×¢×™ ×™×‘×•×× ×™× (××—×•×– ×××•×¦×¢ ×©×œ ×˜×™×¤×•×œ ×‘×¨×™×§×•×œ×™×)"
)
st.plotly_chart(fig3, use_container_width=True)

st.subheader("ğŸ’¬ ×”×¢×¨×•×ª")
st.text_area("×”×•×¡×£ ×”×¢×¨×•×ª ×¢×œ ×‘×™×¦×•×¢×™ ×™×‘×•×× ×™×:", key="comments_3", height=100)

st.write("---")


# ----------------------------------------------------------
# SECTION 4 â€” Recall Severity Distribution
# ----------------------------------------------------------
st.header("âš ï¸ ×”×ª×¤×œ×’×•×ª ×¡×•×’×™ ×¨×™×§×•×œ×™× (×—×•××¨×”)")

if "sug_takala" in recalls.columns:
    severity_dist = recalls["sug_takala"].value_counts().reset_index()
    severity_dist.columns = ["×¡×•×’ ×ª×§×œ×”", "××¡×¤×¨ ×¨×™×§×•×œ×™×"]
    
    fig4 = px.bar(
        severity_dist,
        x="×¡×•×’ ×ª×§×œ×”",
        y="××¡×¤×¨ ×¨×™×§×•×œ×™×",
        title="×”×ª×¤×œ×’×•×ª ×¡×•×’×™ ×ª×§×œ×•×ª ×¨×™×§×•×œ"
    )
    st.plotly_chart(fig4, use_container_width=True)
else:
    st.warning("×”×©×“×” sug_takala ×œ× × ××¦× ×‘× ×ª×•× ×™ ×”-API.")

st.subheader("ğŸ’¬ ×”×¢×¨×•×ª")
st.text_area("×”×•×¡×£ ×”×¢×¨×•×ª ×¢×œ ×—×•××¨×ª ×¨×™×§×•×œ×™×:", key="comments_4", height=100)

st.write("---")
st.caption("××§×•×¨ × ×ª×•× ×™×: data.gov.il | ×–×”×• ×¤×¨×•×™×§×˜ ××™×©×™ ×œ×ª×™×§ ×¢×‘×•×“×•×ª.")