import streamlit as st
import pandas as pd
import requests
from urllib.parse import urlencode
import plotly.express as px

# ----------------------------------------------------------
# PAGE CONFIG
# ----------------------------------------------------------
st.set_page_config(page_title="×œ×•×— ×‘×§×¨×” - ×¨×™×§×•×œ×™× ×œ×¨×›×‘×™×", layout="wide")

# Add RTL CSS for Hebrew alignment
st.markdown("""
<style>
    .stApp {
        direction: rtl;
    }
    .stTextInput > div > div > input {
        direction: rtl;
        text-align: right;
    }
    .stTextArea textarea {
        direction: rtl;
        text-align: right;
    }
    h1, h2, h3, h4, h5, h6, p, div, span {
        direction: rtl;
        text-align: right;
    }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ“Š ×œ×•×— ×‘×§×¨×” - ×¨×™×§×•×œ×™× ×œ×¨×›×‘×™× ×‘×™×©×¨××œ")
st.write("× ×ª×•× ×™× ×—×™×™× ×™×©×™×¨×•×ª ×-API ×©×œ × ×ª×•× ×™ ×”×××©×œ×” ×”×¤×ª×•×—×™×.")

# ----------------------------------------------------------
# CONSTANTS â€“ API RESOURCE IDs
# ----------------------------------------------------------
RECALLS_RID = "2c33523f-87aa-44ec-a736-edbb0a82975e"
PRIVATE_RID = "053cea08-09bc-40ec-8f7a-156f0677aff3"
UNATTENDED_RID = "36bf1404-0be4-49d2-82dc-2f1ead4a8b93"

API_BASE = "https://data.gov.il/api/3/action/datastore_search"


# ----------------------------------------------------------
# API FETCHER WITH PAGINATION
# ----------------------------------------------------------
@st.cache_data(show_spinner=True)
def fetch_full_table(resource_id, max_rows=50000):
    """Fetches up to max_rows rows from the CKAN API with pagination."""
    all_records = []
    limit = 5000
    offset = 0

    while True:
        params = {
            "resource_id": resource_id,
            "limit": limit,
            "offset": offset
        }

        url = API_BASE + "?" + urlencode(params)
        response = requests.get(url)

        if response.status_code != 200:
            st.error(f"×©×’×™××ª API: {response.text}")
            break

        data = response.json()["result"]["records"]
        if not data:
            break

        all_records.extend(data)
        offset += limit

        if len(all_records) >= max_rows:
            break

    df = pd.DataFrame(all_records)
    return df


# ----------------------------------------------------------
# LOAD DATA (LIMITED FOR STREAMLIT PERFORMANCE)
# ----------------------------------------------------------
st.sidebar.header("âš™ï¸ ×”×’×“×¨×•×ª")
MAX_ROWS = st.sidebar.slider("××§×¡×™××•× ×©×•×¨×•×ª ×œ×˜×¢×™× ×” ×œ×›×œ ×˜×‘×œ×”:", 5000, 150000, 50000)

with st.spinner("××•×¨×™×“ × ×ª×•× ×™× ×—×™×™× ×-data.gov.il..."):
    recalls = fetch_full_table(RECALLS_RID, MAX_ROWS)
    private = fetch_full_table(PRIVATE_RID, MAX_ROWS)
    unattended = fetch_full_table(UNATTENDED_RID, MAX_ROWS)

st.success("×”× ×ª×•× ×™× × ×˜×¢× ×• ×‘×”×¦×œ×—×”.")

# ----------------------------------------------------------
# CLEAN COLUMN NAMES (normalize to uppercase as in API)
# ----------------------------------------------------------
recalls.columns = recalls.columns.str.upper()
private.columns = private.columns.str.upper()
unattended.columns = unattended.columns.str.upper()

# Debug: Show available columns
st.sidebar.write("×¢××•×“×•×ª ×–××™× ×•×ª:")
st.sidebar.write("Recalls:", list(recalls.columns))
st.sidebar.write("Private:", list(private.columns))
st.sidebar.write("Unattended:", list(unattended.columns))

# Hebrew column mapping
HEBREW_COLUMNS = {
    # Unattended table
    "MISPAR_RECHEV": "××¡×¤×¨ ×¨×›×‘",
    "RECALL_ID": "××–×”×” ×¨×™×§×•×œ",
    "SUG_RECALL": "×¡×•×’ ×¨×™×§×•×œ",
    "SUG_TAKALA": "×¡×•×’ ×ª×§×œ×”",
    "TEUR_TAKALA": "×ª×™××•×¨ ×ª×§×œ×”",
    "TAARICH_PTICHA": "×ª××¨×™×š ×¤×ª×™×—×”",
    
    # Recalls table
    "TOZAR_CD": "×§×•×“ ×™×¦×¨×Ÿ",
    "TOZAR_TEUR": "×™×¦×¨×Ÿ",
    "DEGEM": "×“×’×",
    "SHNAT_RECALL": "×©× ×ª ×¨×™×§×•×œ",
    "BUILD_BEGIN_A": "×ª×—×™×œ×ª ×™×™×¦×•×¨",
    "BUILD_END_A": "×¡×•×£ ×™×™×¦×•×¨",
    "OFEN_TIKUN": "××•×¤×Ÿ ×ª×™×§×•×Ÿ",
    "TKINA_EU": "×ª×§× ×” EU",
    "YEVUAN_TEUR": "×™×‘×•××Ÿ",
    "TELEPHONE": "×˜×œ×¤×•×Ÿ",
    "WEBSITE": "××ª×¨",
    
    # Private vehicles table
    "TOZERET_CD": "×§×•×“ ×™×¦×¨×Ÿ",
    "SUG_DEGEM": "×¡×•×’ ×“×’×",
    "TOZERET_NM": "×™×¦×¨×Ÿ",
    "DEGEM_CD": "×§×•×“ ×“×’×",
    "DEGEM_NM": "×“×’×",
    "RAMAT_GIMUR": "×¨××ª ×’×™××•×¨",
    "SHNAT_YITZUR": "×©× ×ª ×™×™×¦×•×¨",
    "TZEVA_RECHEV": "×¦×‘×¢ ×¨×›×‘",
    "SUG_DELEK_NM": "×¡×•×’ ×“×œ×§",
    "KINUY_MISHARI": "×›×™× ×•×™ ××¡×—×¨×™"
}


# ----------------------------------------------------------
# PLATE LOOKUP TOOL
# ----------------------------------------------------------
st.subheader("ğŸ” ×‘×“×™×§×ª ××¡×¤×¨ ×¨×™×©×•×™ ×œ×¨×™×§×•×œ×™× ×©×œ× ×˜×•×¤×œ×•")

plate_input = st.text_input("×”×–×Ÿ ××¡×¤×¨ ×¨×™×©×•×™ (×¡×¤×¨×•×ª ×‘×œ×‘×“):")

if plate_input:
    try:
        plate_num = int(plate_input.strip())
        
        # Convert MISPAR_RECHEV to numeric if not already
        unattended["MISPAR_RECHEV"] = pd.to_numeric(unattended["MISPAR_RECHEV"], errors="coerce")
        
        match = unattended[unattended["MISPAR_RECHEV"] == plate_num]

        if len(match) > 0:
            st.error("âš ï¸ ×œ×¨×›×‘ ×©×œ×š ×™×© ×¨×™×§×•×œ ×©×œ× ×˜×•×¤×œ!")

            # Get available columns
            available_cols = list(match.columns)
            st.write(f"×¢××•×“×•×ª ×–××™× ×•×ª: {available_cols}")
            
            # Merge with recalls to get SUG_TAKALA and TEUR_TAKALA if they exist
            if "RECALL_ID" in match.columns and "RECALL_ID" in recalls.columns:
                match_with_details = match.merge(
                    recalls[["RECALL_ID", "SUG_TAKALA", "TEUR_TAKALA"]],
                    on="RECALL_ID",
                    how="left"
                )
            else:
                match_with_details = match

            # Show all available data
            st.write("×¤×¨×˜×™ ×”×¨×™×§×•×œ:")
            
            # Create display dataframe with Hebrew column names
            display_match = match_with_details.copy()
            display_match.columns = [HEBREW_COLUMNS.get(col, col) for col in display_match.columns]
            
            st.dataframe(display_match)
        else:
            st.success("âœ”ï¸ ×”×¨×›×‘ ×©×œ×š ×œ× ××•×¤×™×¢ ×‘×××’×¨ ×”×¨×™×§×•×œ×™× ×©×œ× ×˜×•×¤×œ×•.")
    except Exception as e:
        st.error(f"×©×’×™××”: {str(e)}")
        st.write(f"× ×™×¡×™×ª ×œ×”×–×™×Ÿ: {plate_input}")


# ----------------------------------------------------------
# JOIN: For later graphs
# ----------------------------------------------------------
# Ensure numeric
private["MISPAR_RECHEV"] = pd.to_numeric(private["MISPAR_RECHEV"], errors="coerce")
unattended["MISPAR_RECHEV"] = pd.to_numeric(unattended["MISPAR_RECHEV"], errors="coerce")

# Merge by TOZERET_CD (manufacturer) and DEGEM_NM (model)
joined = private.merge(
    recalls,
    left_on=["TOZERET_CD", "DEGEM_NM"],
    right_on=["TOZAR_CD", "DEGEM"],
    how="inner",
    suffixes=("_PR", "_RC")
)

st.sidebar.write("Joined columns:", list(joined.columns))


# ----------------------------------------------------------
# SECTIONS (SCROLLABLE, NOT TABS)
# ----------------------------------------------------------
st.write("---")


# ----------------------------------------------------------
# SECTION 1 â€” Which Recall Affected Most Vehicles?
# ----------------------------------------------------------
st.header("ğŸš— ×¨×™×§×•×œ×™× ×©×”×©×¤×™×¢×• ×¢×œ ××¡×¤×¨ ×”×¨×›×‘×™× ×”×’×‘×•×” ×‘×™×•×ª×¨")

# Find the correct MISPAR_RECHEV column name after merge
mispar_col = None
for col in joined.columns:
    if "MISPAR_RECHEV" in col:
        mispar_col = col
        break

# Check which columns exist after merge
if mispar_col and "SUG_TAKALA_RC" in joined.columns and "TEUR_TAKALA_RC" in joined.columns:
    recall_counts = (
        joined.groupby(["RECALL_ID", "SUG_TAKALA_RC", "TEUR_TAKALA_RC"])
        .agg(vehicles_affected=(mispar_col, "count"))
        .sort_values("vehicles_affected", ascending=False)
        .reset_index()
    )
    
    # Rename for display
    recall_counts_display = recall_counts.head(20).copy()
    recall_counts_display.columns = ["××–×”×” ×¨×™×§×•×œ", "×¡×•×’ ×ª×§×œ×”", "×ª×™××•×¨ ×ª×§×œ×”", "××¡×¤×¨ ×¨×›×‘×™× ××•×©×¤×¢×™×"]
    
    fig1 = px.bar(
        recall_counts_display,
        x="××–×”×” ×¨×™×§×•×œ",
        y="××¡×¤×¨ ×¨×›×‘×™× ××•×©×¤×¢×™×",
        hover_data=["×¡×•×’ ×ª×§×œ×”", "×ª×™××•×¨ ×ª×§×œ×”"],
        title="20 ×”×¨×™×§×•×œ×™× ×”××•×‘×™×œ×™× ×œ×¤×™ ××¡×¤×¨ ×¨×›×‘×™× ××•×©×¤×¢×™×"
    )
    st.plotly_chart(fig1, use_container_width=True)
elif mispar_col:
    # Fallback: use only RECALL_ID
    recall_counts = (
        joined.groupby("RECALL_ID")
        .agg(vehicles_affected=(mispar_col, "count"))
        .sort_values("vehicles_affected", ascending=False)
        .reset_index()
    )
    
    recall_counts_display = recall_counts.head(20).copy()
    recall_counts_display.columns = ["××–×”×” ×¨×™×§×•×œ", "××¡×¤×¨ ×¨×›×‘×™× ××•×©×¤×¢×™×"]
    
    fig1 = px.bar(
        recall_counts_display,
        x="××–×”×” ×¨×™×§×•×œ",
        y="××¡×¤×¨ ×¨×›×‘×™× ××•×©×¤×¢×™×",
        title="20 ×”×¨×™×§×•×œ×™× ×”××•×‘×™×œ×™× ×œ×¤×™ ××¡×¤×¨ ×¨×›×‘×™× ××•×©×¤×¢×™×"
    )
    st.plotly_chart(fig1, use_container_width=True)
else:
    st.error("×œ× × ××¦× ×¢××•×“×ª MISPAR_RECHEV ×‘× ×ª×•× ×™× ×”×××•×—×“×™×")

st.subheader("ğŸ’¬ ×”×¢×¨×•×ª")
st.text_area("×”×•×¡×£ ×”×¢×¨×•×ª ×¢×œ ×¨×™×§×•×œ×™× ××©×¤×™×¢×™×:", key="comments_1", height=100)

st.write("---")


# ----------------------------------------------------------
# SECTION 2 â€” Recalls Over Time
# ----------------------------------------------------------
st.header("ğŸ“ˆ ×¨×™×§×•×œ×™× ×œ××•×¨×š ×–××Ÿ ×œ×¤×™ ×™×¦×¨×Ÿ")

if "SHNAT_RECALL" in recalls.columns:
    recalls["SHNAT_RECALL"] = pd.to_numeric(recalls["SHNAT_RECALL"], errors="coerce")

trend = (
    recalls.groupby(["SHNAT_RECALL", "TOZAR_TEUR"])
    .size()
    .reset_index(name="count")
)

# Rename for display
trend_display = trend.copy()
trend_display.columns = ["×©× ×ª ×¨×™×§×•×œ", "×™×¦×¨×Ÿ", "××¡×¤×¨ ×¨×™×§×•×œ×™×"]

fig2 = px.line(
    trend_display,
    x="×©× ×ª ×¨×™×§×•×œ",
    y="××¡×¤×¨ ×¨×™×§×•×œ×™×",
    color="×™×¦×¨×Ÿ",
    title="××¡×¤×¨ ×¨×™×§×•×œ×™× ×œ×¤×™ ×™×¦×¨×Ÿ ×œ××•×¨×š ×–××Ÿ"
)
st.plotly_chart(fig2, use_container_width=True)

st.subheader("ğŸ’¬ ×”×¢×¨×•×ª")
st.text_area("×”×•×¡×£ ×”×¢×¨×•×ª ×¢×œ ××’××•×ª ×¨×™×§×•×œ×™×:", key="comments_2", height=100)

st.write("---")


# ----------------------------------------------------------
# SECTION 3 â€” Importer Performance (Attendance Rates)
# ----------------------------------------------------------
st.header("ğŸ­ ×‘×™×¦×•×¢×™ ×™×‘×•×× ×™× - ××—×•×–×™ ×˜×™×¤×•×œ ×‘×¨×™×§×•×œ×™×")

if mispar_col:
    total_affected = (
        joined.groupby("RECALL_ID")
        .agg(total=(mispar_col, "count"))
    )

    unattended_count = (
        unattended.groupby("RECALL_ID")
        .size()
        .to_frame("unattended")
    )

    performance = total_affected.join(unattended_count, how="left").fillna(0)
    performance["attendance_rate"] = (
        (1 - performance["unattended"] / performance["total"]) * 100
    )

    # Join importer
    performance = performance.merge(
        recalls[["RECALL_ID", "YEVUAN_TEUR"]],
        on="RECALL_ID",
        how="left"
    )

    perf_by_importer = performance.groupby("YEVUAN_TEUR")["attendance_rate"].mean().reset_index()
    perf_by_importer.columns = ["×™×‘×•××Ÿ", "××—×•×– ×××•×¦×¢ ×©×œ ×˜×™×¤×•×œ ×‘×¨×™×§×•×œ×™×"]

    fig3 = px.bar(
        perf_by_importer,
        x="×™×‘×•××Ÿ",
        y="××—×•×– ×××•×¦×¢ ×©×œ ×˜×™×¤×•×œ ×‘×¨×™×§×•×œ×™×",
        title="×‘×™×¦×•×¢×™ ×™×‘×•×× ×™× (××—×•×– ×××•×¦×¢ ×©×œ ×˜×™×¤×•×œ ×‘×¨×™×§×•×œ×™×)"
    )
    st.plotly_chart(fig3, use_container_width=True)
else:
    st.error("×œ× × ×™×ª×Ÿ ×œ×—×©×‘ ×‘×™×¦×•×¢×™ ×™×‘×•×× ×™× - ×—×¡×¨×” ×¢××•×“×ª MISPAR_RECHEV")

st.subheader("ğŸ’¬ ×”×¢×¨×•×ª")
st.text_area("×”×•×¡×£ ×”×¢×¨×•×ª ×¢×œ ×‘×™×¦×•×¢×™ ×™×‘×•×× ×™×:", key="comments_3", height=100)

st.write("---")


# ----------------------------------------------------------
# SECTION 4 â€” Recall Severity Distribution
# ----------------------------------------------------------
st.header("âš ï¸ ×”×ª×¤×œ×’×•×ª ×¡×•×’×™ ×¨×™×§×•×œ×™× (×—×•××¨×”)")

if "SUG_TAKALA" in recalls.columns:
    severity_dist = recalls["SUG_TAKALA"].value_counts().reset_index()
    severity_dist.columns = ["×¡×•×’ ×ª×§×œ×”", "××¡×¤×¨ ×¨×™×§×•×œ×™×"]
    
    fig4 = px.bar(
        severity_dist,
        x="×¡×•×’ ×ª×§×œ×”",
        y="××¡×¤×¨ ×¨×™×§×•×œ×™×",
        title="×”×ª×¤×œ×’×•×ª ×¡×•×’×™ ×ª×§×œ×•×ª ×¨×™×§×•×œ"
    )
    st.plotly_chart(fig4, use_container_width=True)
else:
    st.warning("×”×©×“×” SUG_TAKALA ×œ× × ××¦× ×‘× ×ª×•× ×™ ×”-API.")

st.subheader("ğŸ’¬ ×”×¢×¨×•×ª")
st.text_area("×”×•×¡×£ ×”×¢×¨×•×ª ×¢×œ ×—×•××¨×ª ×¨×™×§×•×œ×™×:", key="comments_4", height=100)

st.write("---")
st.caption("××§×•×¨ × ×ª×•× ×™×: data.gov.il | ×–×”×• ×¤×¨×•×™×§×˜ ××™×©×™ ×œ×ª×™×§ ×¢×‘×•×“×•×ª.")